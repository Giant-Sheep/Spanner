\documentclass[a4paper,11pt]{article}
\usepackage{parskip}
\usepackage{a4wide}
\usepackage[named]{algo}

\begin{document}
{\centering{
{\LARGE{Geometric Algorithms - 2IL55\\Spanner project}}
\newline
{\large{\\Matias Piispanen\\Marieke Zantema\\}}
}}

\section{Introduction}
Networks can be found in all sorts of everyday problems. Whenever it comes to connecting `things' to each other -- cities connected by railroads, computers connected by cables, buildings connected by the sewer -- the problem is a network problem. In almost all cases it is not feasible to connect all nodes to all other nodes, so it will be necessary to construct a better network. It is often desired to have a small size (number of railroads, cables or pipes), a small weight (amount of railroad) and a small dilation (the distance via the network should not be more than the real distance multiplied by a constant $t$).
We implement three different algorithms to make a network with a given maximum dilation $t$, or $t$-spanner for short. One algorithm is based on a WSPD-decomposition, another is a greedy algorithm and the third algorithm is a cone-based algorithm. To test our algorithms, we generate random points and look at the properties of the spanners created by the various algorithms.

\section{The algorithms}

\subsection{WSPD-based}

A WSPD-based spanner algorithm first constructs an s-Well Separated Pair Decomposition and then simply connects representatives of each found pair sets with an edge.

The algorithms presented in the lecture slides will be used to implement the WSPD-based spanner algorithm. The s-Well Separated Pair Decomposition algorithm is based on constructing a quadtree and identifying which nodes make a well separated pair. The following algorithm was presented on the lectures:

\begin{algorithm}{wsPairs}{
  \qprocedure{wsPairs}
  \qinput{$u$, $v$, Quadtree $T$, $s$}
  \qoutput{s-Well Separated Pair Decomposition $W$}
}
\qif $repu(u)$ or $rep(v)$ is $empty$ \\
  \qreturn $\emptyset$ \\
\qelse \qfi \qif $u$ and $v$ are s-Well Separated \\
  \qreturn ($u$, $v$)  \qfi \\
\qif $level(u) < level(v)$ \\
  swap $u$ and $v$ \qfi \\
Let $u_1, u_2, ..., u_m$ denote the children of $u$ in $T$ \\
\qreturn $Sum_i$ wsPairs($u_i$, $v_i$, T, s)
\end{algorithm}

Initially the algorithm will be generated using a regular quadtree. The algorithm can be made more efficient by using compressed quadtrees which makes the running time of the s-WSPD construction $O(n \log n + s^d n)$. After the s-WSPD has been constructed, the spanner can be generated by simply connecting one representative of each pair set to another with the following algorithm.

\begin{algorithm}{WSPD-Spanner}{
  \qprocedure{WSPD-Spanner}
  \qinput{Point set $V$, $t  > 1$}
  \qoutput{t-Spanner $G(V,E)$}}
  $s \qlet 4*(t+1)(t-1)$ \\
  $W \qlet wsPairs(root_T, root_T, T, s)$ \\
  $E \qlet \emptyset$ \\
  \qfor ($A_i, B_i$ in $W$ \\
  Select arbitrary node $u$ in $A_i$ and $v$ in $B_i$ \\
  Add edge ($u, v$) to $E$ \qfi \\
  \qreturn $G(V, E)$
\end{algorithm}

The running-time of this algorithm is $O(n \log n)$, therefore the overall complexity of the s-WSPD-based spanner algorithm is $O(n \log n + s^d n)$ if compressed quadtrees are used. An implementation with regular quadtrees has running-time of $O((d-1) n) + s^d n)$ due to the slower construction time of the quadtree.

\subsection{Greedy}

The greedy algorithm is the simplest, and also the slowest, algorithm for constructing a geometric spanner. It is still a good comparison for the more complex algorithms for seeing how much better quality spanners they can construct compared to the greedy algorithm.

The greedy algorithm starts by listing all point pairs based on their distance. The initial spanner graph has no edges. The algorithm then checks for each point pair whether the dilation for that pair is greater than $t$ and adds an edge between them if it is.

There are $n^2$ pairs that have to be compared. Finding a shortest path with Dijkstra's algorithm takes $O(|E| + n \log n)$ time, where $|E|$ is the number of edges, so the total running time of the algorithm is $O(n^2(|E| + n \log n))$.

\subsection{Theta spanner}
To construct a theta spanner for the given set of points and the given maximum dilation, first the required number of cones is calculated. In the lecture notes about spanners, the formula $t \geq 1/(1-\sin(\phi/2))$ is stated. I think this should be $t \leq 1/(1-\sin(\phi/2))$, which can be rewritten to $k \geq \pi/(\arcsin(1-1/t))$ where $\phi=2\pi/k$. This is used to calculate the minimum number of cones needed.
\\Each cone gives rise to an orientation: the points are rotated about the origin until the bisector of the cone is a horizontal ray in positive $x$-direction. Now one of the cone's rays lies in the half-plane $y>0$, this ray is called $r_1$, and the other ray ($r_2$) lies in the half-plane $y<0$.
\\For each orientation, a sweepline algorithm is used to find for each point the leftmost point in the cone. The sweepline is parallel to $r_1$ and sweeps in positive $x$-direction. So the event queue of this algorithm is a vector that stores all points, sorted by `distance' from $r_1$ where the `distance' is negative if the point lies above $r_1$.
\\The status is a non-trivial data structure. It starts as a binary tree but its leaves and internal nodes are `cut away' when the sweepline algorithm is being executed. The points are stored in the leaves of this tree and they are sorted by `distance' from $r_2$. The internal nodes contain the leftmost (smallest $x$-coordinate) point of the subtree plus the point that is leftmost in the subtree (but does not necessarily have the smallest $x$-coordinate). Only one operation is needed for this algorithm: $\textsc{DeleteAndFindLeftmost}(p)$. This operation involves searching for the point $p$ in the tree by walking from the root to the leaf where $p$ is stored, deleting $p$, and going back to the root. Since it is not necessary to add points, deleting a point involves only deleting and not re-building the tree such that it remains a binary tree. The depth of the tree does not increase, so \textsc{DeleteAndFindLeftmost} always runs in $O(\log n)$ time. When walking from $p$ to the root, the tree is updated (the leftmost point stored in an internal node may have to be changed or an internal node may have to be deleted) and the leftmost point that is to the right of $p$ is searched for. After $\textsc{DeleteAndFindLeftmost}(p)$, the tree is updated and the leftmost point to the right of $p$ is returned.
\\An event occurs when the sweepline reaches a point $p$. Then $\textsc{DeleteAndFindLeftmost}(p)$ is called, and the edge from $p$ to the leftmost point is added to the set of edges, if it wasn't there already.
\\The running time of this algorithm would have been $O(kn \log n)$ if it wasn't necessary to verify that no edge is added twice. Checking that an edge is new is done by simply looking at all edges before adding a new edge, which takes $O(n^2)$ time in the worst case. This is done for each edge, giving a total running time of $O(kn^4$) in the worst case. If a more elegant algorithm was used, like storing the edges in a binary search tree and only adding edges that are not there yet, the running time would be $O(k n^2 \log n)$ in the worst case and $O(k n \log n)$ if the number of edges is small ($O(n)$ instead of $O(n^2)$).

\section{Experimental setup}
We have written code that generates a text file in the following format. The first line contains one integer, namely the number of points. The second line contains two integers, $a$ and $b$, that indicate the maximum dilation $t=a/b$. The remaining lines contain the points, that is, each line contains two positive integers: the $x$- and $y$-coordinate of the point. Note that this is the same format as the format for the data challenge.
The points for the text file are generated randomly, but the code asserts that no two points are the same. When calling the function GenerateData, one must specify the number of points, the maximum value of $t$ and the maximum value of the $x$- and $y$-coordinates.

We are testing the spanners with respect to their size, weight, maximum degree and the dilation. The actual running times of the algorithms will also be measured by running the algorithms multiple times and calculating the average running times.

The GLUT API is used to get inputs from keyboard and visualizing the spanners by using the OpenGL library.

\end{document} 